---
title: "Final_R_Analysis"
output: html_document
date: "2024-10-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Set the CRAN mirror (UK in this case)
options(repos = c(CRAN = "https://cran.ma.imperial.ac.uk/"))
```

## Section 0: Overview

In this section we will be analysing the reproduction rate of COVID-19 in a number of countries. We will be conducting this analysis through the use of the Random Forest regression model, first taking a look at key indicators, including the Mean Stringency Index, Community Health Index, Government Response Index and Economic Support Index throughout the pandemic. 

These collectively capture policy response, temporal progression of the virus and public health conditions, allowing us to take a comprehensive approach to predicting and understanding COVID-19's reproduction rate. We use mean squared error (MSE) as our performance metric, and in this study we aim to improve a model to be able to capture the complexities of COVID-19 transmission.

## Section 1: Necessary Imports


```{r message=FALSE, warning=FALSE}
#Libraries

library(readxl)
library(ranger)
library(rpart)
library(rpart.plot)
library(partykit)
library(dplyr)
library(Metrics)
library(ggplot2)
```

## Section 2: Data Access


#### Train Data

```{r}
#For the author

# Define the path to your data

data_path = "/Users/harrywilson/Desktop/DataScienceToolbox/Assessment-1-Supervised-Prediction/Train_and_Test_data"


# Construct the full file path for the train Excel file

#train_data_path = file.path(data_path, "train.csv")


# Read the Excel/csv file 

#train_data = read_excel(train_data_path)

train_data <- read.csv(file.path(data_path, "train.csv"))

```

```{r}
#For the reader

# Define the path to your data

#data_path = "[replace with your path]"



# Construct the full file path for the train Excel file

#train_data_path = file.path(data_path, "train.xlsx")



# Read the Excel file (using the readxl package)

#train_data = read_excel(train_data_path)
```

#### Test Data

```{r}
#For the author

# Define the path to your data

data_path = "/Users/harrywilson/Desktop/DataScienceToolbox/Assessment-1-Supervised-Prediction/Train_and_Test_data"



# Construct the full file path for the Excel file

test_data_path = file.path(data_path, "test.xlsx")


# Read the Excel file

test_data = read_excel(test_data_path)

#The mean stringency has a different name to in the training data, so this is going to help us later

# Renaming the column in test_data (if it has the same name)
colnames(test_data)[colnames(test_data) == "mean_stringency...5"] <- "mean_stringency"

```


```{r}
#For the reader

# Define the path to your data

#data_path = "[replace with your path]"



# Construct the full file path for the Excel file

#test_data_path = file.path(data_path, "test.xlsx")


# Read the Excel file

#test_data = read_excel(test_data_path)
```

```{r}
head(test_data)
head(train_data)
```

This allows us to check if our data set has been installed correctly, as if it has we should see the first few rows and columns of our data set.


## Section 3: Implementing the Model

#### Vanilla Model

```{r}
# Specify the columns for independent variables and dependent variable
independent_vars = train_data[, c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since")]
dependent_var = train_data$reproduction_rate

# Combine into a new data frame
model_data = data.frame(dependent_var, independent_vars)

# Remove rows with missing values in any of the variables
model_data_complete = na.omit(model_data)

# Fit the random forest model using only complete cases
rf_model <- ranger(
  formula = dependent_var ~ .,    # Use all independent variables
  data = model_data_complete,      # Use the complete dataset
  num.trees = 50,                # Number of trees in the forest
  importance = 'impurity',        # Measure feature importance
  mtry = 2, # Adjust this based on the number of independent variables
  sample.fraction = 0.5,
  num.threads = 1,
  replace = FALSE,
)

# View the model summary
print(rf_model)
```

```{r}
# Specify our independent variables
required_columns <- c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since")

# Extract the independent variables from test_data
test_independent_vars <- test_data[, required_columns]

# Combine test independent variables and dependent variable into one data frame
test_data_combined <- data.frame(test_independent_vars, reproduction_rate = test_data$reproduction_rate)

# Remove rows with missing values in any of the columns (independent or dependent)
test_data_complete <- na.omit(test_data_combined)

# Separate independent variables and actual values after omitting rows with NAs
test_independent_vars_complete <- test_data_complete[, required_columns]  # Independent variables
actual_values_complete <- test_data_complete$reproduction_rate  # Dependent variable

# Check the number of rows for consistency
cat("Number of rows in independent variables:", nrow(test_independent_vars_complete), "\n")
cat("Number of rows in actual values:", length(actual_values_complete), "\n")

# Make predictions using the complete test data
predictions <- predict(rf_model, data = test_independent_vars_complete)

# View the predicted values
predicted_values <- predictions$predictions

# Calculate RMSE and MAE to evaluate prediction accuracy
mse <- mse(actual_values_complete, predicted_values)  # MSE calculation using function
mae <- mae(actual_values_complete, predicted_values)  # MAE calculation using function

# Print the error metrics
cat("MSE:", mse, "\n")
cat("MAE:", mae, "\n")

```

#### Bootstrapping Our Model

We see our initial model has produced an acceptable MSE, so we see our independent variables are giving us a good prediction. However, to improve the reliability of our model we will apply bootstrapping techniques. This is a re-sampling method, enabling a more accurate estimation of model uncertainty by generating multiple samples from our original data set. Incorporating this approach should refine our models predictions, giving us a lower MSE.


```{r}
# Specify the columns for independent variables and dependent variable
independent_vars = train_data[, c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since")]
dependent_var = train_data$reproduction_rate

# Combine into a new data frame
model_data = data.frame(dependent_var, independent_vars)

# Remove rows with missing values in any of the variables
model_data_complete = na.omit(model_data)

rf_model_tuned <- ranger(
  formula = dependent_var ~ .,    
  data = model_data_complete,      
  num.trees = 50,                
  importance = 'impurity',        
  mtry = 2, 
  sample.fraction = 0.5,
  num.threads = 1,
  replace = TRUE,
)


# View the model summary
print(rf_model_tuned)

```

```{r}
required_columns <- c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since")
# Step 1: Extract the independent variables from test_data
test_independent_vars <- test_data[, required_columns]

# Step 2: Combine test independent variables and dependent variable into one data frame
test_data_combined <- data.frame(test_independent_vars, reproduction_rate = test_data$reproduction_rate)

# Step 3: Remove rows with missing values in any of the columns (independent or dependent)
test_data_complete <- na.omit(test_data_combined)

# Step 4: Separate independent variables and actual values after omitting rows with NAs
test_independent_vars_complete <- test_data_complete[, required_columns]  # Independent variables
actual_values_complete <- test_data_complete$reproduction_rate  # Dependent variable

# Check the number of rows for consistency
cat("Number of rows in independent variables:", nrow(test_independent_vars_complete), "\n")
cat("Number of rows in actual values:", length(actual_values_complete), "\n")

# Step 5: Make predictions using the complete test data
predictions <- predict(rf_model_tuned, data = test_independent_vars_complete)

# View the predicted values
predicted_values <- predictions$predictions

# Step 6: Calculate RMSE and MAE to evaluate prediction accuracy
mse <- mse(actual_values_complete, predicted_values)  # MSE calculation using function
mae <- mae(actual_values_complete, predicted_values)  # MAE calculation using function

# Print the error metrics
cat("MSE:", mse, "\n")
cat("MAE:", mae, "\n")

```

After applying bootstrapping our performance metric slightly improves. The reduction, though minimal, demonstrates the value of bootstrapping. This highlights the Random Forest's reliability, however indicates further adjustments may need to be made beyond resampling to thoroughly improve our model.

#### Changing Independent Variables

To further improve the predictive accuracy of our model, we introduce additional independent variables, looking at total cases and deaths, along with new cases and deaths. These variables offer even more detail on the pandemic's progression. By expanding the model's feature set, we enhance its ability to understand COVID-19 transmission dynamics.


```{r}
# Specify the columns for independent variables and dependent variable
independent_vars = train_data[, c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since", "total_cases", "total_deaths", "new_cases", "new_deaths")]
dependent_var = train_data$reproduction_rate

# Combine into a new data frame
model_data = data.frame(dependent_var, independent_vars)

# Remove rows with missing values in any of the variables
model_data_complete = na.omit(model_data)

rf_model_tuned <- ranger(
  formula = dependent_var ~ .,    # Use all independent variables
  data = model_data_complete,      # Use the complete dataset
  num.trees = 50,                # Number of trees in the forest
  importance = 'impurity',        # Measure feature importance
  mtry = 2, # Adjust this based on the number of independent variables
  sample.fraction = 0.5,
  num.threads = 1,
  replace = TRUE,
)


# View the model summary
print(rf_model_tuned)

```


```{r}
required_columns <- c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since", "total_cases", "total_deaths", "new_cases", "new_deaths")
# Step 1: Extract the independent variables from test_data
test_independent_vars <- test_data[, required_columns]

# Step 2: Combine test independent variables and dependent variable into one data frame
test_data_combined <- data.frame(test_independent_vars, reproduction_rate = test_data$reproduction_rate)

# Step 3: Remove rows with missing values in any of the columns (independent or dependent)
test_data_complete <- na.omit(test_data_combined)

# Step 4: Separate independent variables and actual values after omitting rows with NAs
test_independent_vars_complete <- test_data_complete[, required_columns]  # Independent variables
actual_values_complete <- test_data_complete$reproduction_rate  # Dependent variable

# Check the number of rows for consistency
cat("Number of rows in independent variables:", nrow(test_independent_vars_complete), "\n")
cat("Number of rows in actual values:", length(actual_values_complete), "\n")

# Step 5: Make predictions using the complete test data
predictions <- predict(rf_model_tuned, data = test_independent_vars_complete)

# View the predicted values
predicted_values <- predictions$predictions

# Step 6: Calculate RMSE and MAE to evaluate prediction accuracy
mse <- mse(actual_values_complete, predicted_values)  # MSE calculation using function
mae <- mae(actual_values_complete, predicted_values)  # MAE calculation using function

# Print the error metrics
cat("MSE:", mse, "\n")
cat("MAE:", mae, "\n")

```




#### Adjusting Hyperparameters 

In my final iteration of my model, I tuned key hyperparameters. I increased the number of trees from 50 to 350, along with modifying the sample fraction from 0.5 to 1. Overall, these hyperparameter adjustments aim to optimise the model's ability to predict by enhancing the diversity of the trees, whilst maintaining access to our complete dataset for training.

##### Understanding Our Hyperparameters

Adjusting "num.trees = 50" to "num.trees = 350" increases the number of decision trees in our forest. This should improve performance by reducing variane, and enhancing stability in our model.

We kept "mtry = 2", which means the model selects two independent variables at random to consider at each split. this introduces randomness into our model, and helps to prevent overfitting.

Changing "sample.fraction" to 1 means the model uses the entire dataset for training at each tree. However, setting "sample.fraction = 0.5" means only half the dataset is used at each tree. This is advantageous to ensuring all data contributes to our model.

We changed "num.threads = 3", this means we allow the algorithm to utlise three CPU threads simultaneously. This can speed up our training process, specifically because we have a large dataset, as it allows multiple trees to be built concurrently.

```{r}
# Specify the columns for independent variables and dependent variable
independent_vars = train_data[, c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since", "total_cases", "total_deaths", "new_cases", "new_deaths")]
dependent_var = train_data$reproduction_rate

# Combine into a new data frame
model_data = data.frame(dependent_var, independent_vars)

# Remove rows with missing values in any of the variables
model_data_complete = na.omit(model_data)

rf_model_tuned <- ranger(
  formula = dependent_var ~ .,    # Use all independent variables
  data = model_data_complete,      # Use the complete dataset
  num.trees = 350,                # Number of trees in the forest
  importance = 'impurity',        # Measure feature importance
  mtry = 2, # Adjust this based on the number of independent variables
  sample.fraction = 1,
  num.threads = 3,
  replace = TRUE,
)


# View the model summary
print(rf_model_tuned)
```

```{r}
required_columns <- c("Mean_Stringency_Index", "CH_Index", "Gov_Resp_Index", "Econ_Sup_Index", "days_since", "total_cases", "total_deaths", "new_cases", "new_deaths")
# Step 1: Extract the independent variables from test_data
test_independent_vars <- test_data[, required_columns]

# Step 2: Combine test independent variables and dependent variable into one data frame
test_data_combined <- data.frame(test_independent_vars, reproduction_rate = test_data$reproduction_rate)

# Step 3: Remove rows with missing values in any of the columns (independent or dependent)
test_data_complete <- na.omit(test_data_combined)

# Step 4: Separate independent variables and actual values after omitting rows with NAs
test_independent_vars_complete <- test_data_complete[, required_columns]  # Independent variables
actual_values_complete <- test_data_complete$reproduction_rate  # Dependent variable

# Check the number of rows for consistency
cat("Number of rows in independent variables:", nrow(test_independent_vars_complete), "\n")
cat("Number of rows in actual values:", length(actual_values_complete), "\n")

# Step 5: Make predictions using the complete test data
predictions <- predict(rf_model_tuned, data = test_independent_vars_complete)

# View the predicted values
predicted_values <- predictions$predictions

# Step 6: Calculate RMSE and MAE to evaluate prediction accuracy
mse <- mse(actual_values_complete, predicted_values)  # MSE calculation using function
mae <- mae(actual_values_complete, predicted_values)  # MAE calculation using function

# Print the error metrics
cat("MSE:", mse, "\n")
cat("MAE:", mae, "\n")

```

#### Visualising Our Random Forest

As we have a Random Forest with 350 trees, it's very computationally expensive to plot the whole thing, along with being more complex to understand. Instead, we choose to plot a segment of the data.

```{r}
# Fit a decision tree model
dt_model <- rpart(dependent_var ~ Mean_Stringency_Index + CH_Index + Gov_Resp_Index + Econ_Sup_Index + days_since + total_cases + total_deaths + new_cases + new_deaths, data = model_data_complete)

# Plot the decision tree
rpart.plot(dt_model, main = "Decision Tree from Training Data")

```

We can also adjust hyperparameters within our plot to increase the number of decision trees, whilst also keeping the plot manageable. 

```{r}
dt_model_3 <- rpart(
  dependent_var ~ Mean_Stringency_Index + CH_Index + Gov_Resp_Index + Econ_Sup_Index + days_since + total_cases + total_deaths + new_cases + new_deaths, 
  data = model_data_complete, 
  control = rpart.control(minsplit = 10, cp = 0.005)
)
rpart.plot(dt_model_3, main = "Complex Decision Tree with minsplit = 10 and cp = 0.005")
```

#### Understanding Our Random Forest

Here, our sub-section of our final random forest is composed of numerous decision trees, splitting data based on our independent variables. For example our first tree splits up our data based on if the days since the start of the pandemic has exceeded or met 764. If so, 33% of our data has a predicted value of 0.75 for our reproduction rate. If no, 67% of our data has a predicted value of 1. Our random forest does this multiple times, looking at our different independent variables.

## Section 4: Visualising Model Success


#### Scatter Plot Visualising Actual Reproduction Rates vs. Our Predicted Rates for all Countries
```{r}
# Step 1: Extract the independent variables and dependent variable (reproduction rate)
test_data_combined <- data.frame(
  test_data[, required_columns],  # Independent variables
  reproduction_rate = test_data$reproduction_rate  # Dependent variable
)

# Step 2: Remove rows with missing values across all required columns
test_data_complete <- na.omit(test_data_combined)

# Step 3: Separate independent variables and actual values after removing NAs
test_independent_vars_complete <- test_data_complete[, required_columns]
actual_values_complete <- test_data_complete$reproduction_rate

# Step 4: Make predictions using the complete test data
predictions <- predict(rf_model_tuned, data = test_independent_vars_complete)
predicted_values <- predictions$predictions

# Step 5: Create a data frame with actual and predicted values for plotting
results <- data.frame(
  actual_reproduction_rate = actual_values_complete,
  predicted_reproduction_rate = predicted_values
)

# Step 6: Plot actual vs. predicted reproduction rates
library(ggplot2)
ggplot(results, aes(x = actual_reproduction_rate, y = predicted_reproduction_rate)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +  # 1:1 line for reference
  labs(
    title = "Actual vs. Predicted COVID-19 Reproduction Rates",
    x = "Actual Reproduction Rate",
    y = "Predicted Reproduction Rate"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

#### Scatter Plot of Our Residuals

```{r}
# Step 1: Calculate residuals
results <- data.frame(
  actual_reproduction_rate = actual_values_complete,
  predicted_reproduction_rate = predicted_values
)
results$residuals <- results$actual_reproduction_rate - results$predicted_reproduction_rate

# Step 2: Plot residuals against predicted reproduction rates
ggplot(results, aes(x = predicted_reproduction_rate, y = residuals)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +  # Reference line at zero
  labs(
    title = "Residuals Plot for COVID-19 Reproduction Rate Predictions",
    x = "Predicted Reproduction Rate",
    y = "Residuals (Actual - Predicted)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```


## Section 5: References






