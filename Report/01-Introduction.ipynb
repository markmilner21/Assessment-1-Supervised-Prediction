{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "\n",
    "The primary objective of this project is to develop and compare the performance of multiple regression models in the context of predicting the COVID-19 reproduction rate for countries with unavailable data, such as North Korea. To tackle the challenge of predicting reproduction rate for North Korea, where data is largely inaccessible, we will consider alternative countries for which we do have the necessary covariate data and target variable data. This enables us to test the performance our various models, establish which model has performed best on our test data and draw insights that could then be applied to similar regions with limited data availability when applied to a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "Brief rationale for why we initially selected these models (try get a reference in here). Brief Mathematical explaination\n",
    "\n",
    "## 1. Linear Regression:\n",
    "\n",
    "The implementation of the linear model serves as a baseline model, acting as a benchmark against which the more complex models we implement can be compared [1]. Additionally, linear regression is simple and provides an adequate description of the linear relationship between input and output variables due to its straightforward formulation and the interpretability of coefficient magnitudes (The magnitude of the coefficient indicates the strength of the relationship between the predictor and the response variable) [2]. \n",
    "\n",
    "\n",
    "The basic linear regression model can be expressed mathematically as follows:\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n \n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $Y$ is the dependent variable (target variable), i.e. the variable we predict (in this case, COVID-19 reproduction rate).\n",
    "- $X_1, X_2, \\ldots, X_n$ are the independent variables (predictor variables) that are used to predict $Y$.\n",
    "- $\\beta_0$ is the y-intercept of the regression line\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_n $ are the coefficients corresponding to each independent variable. These are adjusted throughout training of the models to minimise the mean squared error between our predicted value for the target variable's true real value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2. KNN:\n",
    "\n",
    "KNN acts as a more complex model, which relies on proximity in feature space. KNN is relatively easy to implement, whilst also being adaptible to a wide variety of datasets [3]. The non-parametric nature of KNN makes it flexible as it does not assume an underlying distribution for the data (unlike a linear regression model). When using a suitable number of neighbors, KNN can be robust to noise, and can be computationally efficient for different sizes of dataset. The structure of a KNN algorithm [4] for regression is as follows:\n",
    "\n",
    "- Features can be scaled using scalers such as StandardScaler or RobustScaler, to ensure that some featrures do not have disproportionate influence. This could happen if, for example, a specific feature has very large values. Since KNN is distance based, this will mean it has increased influence even though it is not necessarily more important as a feature.\n",
    "- The algorithm finds the k-nearest neighbors from the training set to a given point in the test set. Distance metrics include Euclidean and Manhattan.\n",
    "- KNN predicts values by averaging the target values of these k-nearest neighbors.\n",
    "\n",
    "## 3. RF: \n",
    "\n",
    "Random Forest (RF) is a complex machine learning algorithm suitable to deal with the non-linear results from our COVID-19 training data. As an ensemble method [1], the model creates multiple decision trees using different subsets of data and averaging their predictions. This therefore helps with overfitting. Random Forestâ€™s performance is powerful for considering missing values or noisy data, meaning it is a great model for a real-world dataset like this where results can vary massively. \n",
    "\n",
    "The random forest algorithm works as follows [2]:  \n",
    "\n",
    "Bootstrap Sampling: We randomly sample our training data to create multiple bootstrap samples. \n",
    "\n",
    "Build Decision Trees: For each bootstrap sample, construct a decision tree. At each node of the tree randomly select a subset of the independent random variables. Then evaluate all splits and choose the split which maximises purity. \n",
    "\n",
    "Average Predictions: We aggregate predictions from all our decision trees to produce our final prediction. \n",
    "\n",
    "Evaluate Model: Finally, we evaluate our model using a performance metric on test date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metric Selection and justification\n",
    "\n",
    "When evaluating the performance of regression models, specifically linear regression, K-Nearest Neighbours and Random Forest on a large dataset, we chose to use Mean Squared Error (MSE). MSE measures the average squared difference between actual and predicted values. We chose this as our performance metric due to it being a default metric for evaluation of the performance for most regression algorithms [5], whilst also being easy to interpret for the reader. This is because the model with the lowest MSE is our preferred model as it demonstrates better fitting to the data.  \n",
    "\n",
    "We also chose MSE due to its valuable role in feature selection. For complex models, MSE can help assess the relative importance of each feature. This helps understand which features are essential to the model's predictive capability, whilst also seeing which can be ignored to simplify the model. \n",
    "\n",
    "The mean squared error can be expressed mathematically as follows:\n",
    "\n",
    "$$ \n",
    "\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \n",
    "\n",
    "$$ \n",
    "\n",
    "  \n",
    "\n",
    "Where: \n",
    "\n",
    "- $n$ is the total number of data points. \n",
    "\n",
    "- $y_i$ is the actual value of the target variable for the $i-th$ data point. \n",
    "\n",
    "- $\\hat{y}_i$ is the predicted value for the $i-th$ data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Hypothesis \n",
    "\n",
    "When predicting the COVID-19 reproduction rate through the pandemic, we expect changes in public health measures, government response and other socio-economic factors to impact the reproduction rate of the virus in complex, non-linear ways, making this a challenging prediction.  \n",
    "\n",
    "  \n",
    "\n",
    "- Linear Regression: We expect linear regression to struggle in capturing this complex, non-linear relationship very well, given its simplicity. We expect this model to establish a rough trend, but sharp peaks and dips caused by sudden outbreaks or policy change will be more difficult to capture.   \n",
    "\n",
    "  \n",
    "\n",
    "- K-Nearest Neighbours Regression: When using KNN, we use the proximity of similar data points to make predictions. We expect much improved predictions over the linear model as KNN can capture non-linear patterns [6]. However, we think KNN may struggle with extreme shifts in reproduction rate, as it relies on localised patterns.  \n",
    "\n",
    "  \n",
    "\n",
    "- Random Forest: We expect Random Forest to outperform both linear regression and KNN [7], as it combines decision trees, which help capture the complex, non-linear interactions. The Random Forest should handle variable shifts more robustly by effectively capturing interactions among predictors such as community health index, and days since the pandemic began.  \n",
    "\n",
    "  \n",
    "\n",
    "To summarise, we hypothesise that linear regression will lag behind both Random Forest and KNN. Whilst KNN will show improvement on this model, Random Forest is expected to achieve the highest accuracy, so in our case, the lowest MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Bishop, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.\n",
    "\n",
    "[2] MLA: Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. 2nd ed., Springer, 2009.\n",
    "\n",
    "[3] https://www.ibm.com/topics/knn\n",
    "\n",
    "[4] https://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/#How_Does_the_KNN_Algorithm_Work?\n",
    "\n",
    "[5] https://towardsdatascience.com/https-medium-com-chayankathuria-regression-why-mean-square-error-a8cad2a1c96f\n",
    "\n",
    "[6] https://medium.com/ml-with-arpit-pathak/k-nearest-neighbors-algorithm-a9559b960fe5\n",
    "\n",
    "[7] https://blog.devgenius.io/knn-and-random-forests-on-diabetes-data-447cacb727f2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
